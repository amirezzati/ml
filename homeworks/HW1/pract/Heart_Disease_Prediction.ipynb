{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QU5zmW1lBAi"
      },
      "source": [
        "In this notebook, we are looking for the diagnosis of heart disease among patients using the [heart disease dataset](https://www.kaggle.com/johnsmith88/heart-disease-dataset). First, read the information about the different features, then answer the questions in each section using the attached data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utNwgYmlKvfm"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjntS4nxH4Hs"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycgOZilIJ-IO"
      },
      "source": [
        "In this notebook, you cannot use scikit learn and other libraries, except for those imported below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA04oziCHqpP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNo6F7XEH7p3"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1KtMuwCmomz"
      },
      "source": [
        "Load dataset csv file into a data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Z3egeyH-g9"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "df ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phw5_4uEIgyY"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkxL1k5Onuvj"
      },
      "source": [
        "In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. In this section, you should analyze the data. You can use the functions provided by the Pandas library. You can use analysis such as null checking of features, number of features and samples, and type of features. But don't stop there and search for it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2qsSen8X1qv"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOo1N_ZaKHPg"
      },
      "source": [
        "## Analysis of Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fnTddu9sTll"
      },
      "source": [
        "As you have probably noticed, in the dataset that you checked, some features are discrete and the rest are continuous. The following code specifies continuous and discrete features for you. **Note**: In the cells below, `df` is the same dataframe that you loaded in the previous section. You can change its name according to your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIcPajwSJj11",
        "outputId": "d9551a1e-e668-4d00-8dce-87c48bb62673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 14 features found in the data\n"
          ]
        }
      ],
      "source": [
        "feature_list = [feature for feature in df.columns]\n",
        "print(\"There are\",len(feature_list),\"features found in the data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3n2gCAoJmdr",
        "outputId": "65132134-22aa-49bb-8d40-384f016f09ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete Variables Count: 9\n",
            "Discrete features are  ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'target']\n",
            "Continuous Variables Count: 5\n",
            "Continuous features are  ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n"
          ]
        }
      ],
      "source": [
        "#Print Discrete Feature Data\n",
        "discrete_feature=[feature for feature in feature_list if len(df[feature].unique())<25]\n",
        "print(\"Discrete Variables Count: {}\".format(len(discrete_feature)))\n",
        "print(\"Discrete features are \",discrete_feature)\n",
        "\n",
        "#Print Continuous Feature Data\n",
        "cont_feature=[feature for feature in feature_list if len(df[feature].unique())>25]\n",
        "print(\"Continuous Variables Count: {}\".format(len(cont_feature)))\n",
        "print(\"Continuous features are \",cont_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zygi7E6ekk4q"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js3fx5A2lnR6"
      },
      "source": [
        "### Stochastic Gradient Descent\n",
        "\n",
        "We will implement the perceptron algorithm in python 3 and numpy. The perceptron will learn using the stochastic gradient descent algorithm (SGD). Gradient Descent minimizes a function by following the gradients of the cost function.\n",
        "\n",
        "### Calculating the Error\n",
        "\n",
        "To calculate the error of a prediction we first need to define the objective function of the perceptron.\n",
        "\n",
        "#### Hinge Loss Function\n",
        "\n",
        "To do this, we need to define the loss function, to calculate the prediction error. We will use hinge loss for our perceptron:\n",
        "\n",
        "$$c(x, y, f(x)) = (1 - y * f(x))_+$$\n",
        "\n",
        "$c$ is the loss function, $x$ the sample, $y$ is the true label, $f(x)$ the predicted label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQRK4oiglp2z"
      },
      "source": [
        "This means the following:\n",
        "$$\n",
        "c(x, y, f(x))=\n",
        "\\begin{cases}\n",
        "    0,& \\text{if } y * f(x)\\geq 1\\\\\n",
        "    1-y*f(x),              & \\text{else}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "So consider, if y and f(x) are signed values $(+1,-1)$:\n",
        "\n",
        "<ul>\n",
        "    <li>the loss is 0, if $y*f(x)$ are positive, respective both values have the same sign.</li>\n",
        "    <li>loss is $1-y*f(x)$ if $y*f(x)$ is negative</li>\n",
        "</ul>\n",
        "\n",
        "#### Objective Function\n",
        "\n",
        "As we defined the loss function, we can now define the objective function for the perceptron:\n",
        "\n",
        "$$l_i(w) = \\big(-y_i \\langle x_i,w \\rangle\\big)_+$$\n",
        "\n",
        "We can write this without the dot product with a sum sign:\n",
        "\n",
        "$$l_i(w) = (-y_i \\sum_{i=1}^n x_iw)_+$$\n",
        "\n",
        "So the sample $x_i$ is misclassified, if $y_i \\langle x_i,w \\rangle \\leq 0$. The general goal is, to find the global minima of this function, respectively find a parameter $w$, where the error is zero.\n",
        "\n",
        "#### Derive the Objective Function\n",
        "\n",
        "To do this we need the gradients of the objective function. The gradient of a function $f$ is the vector of its partial derivatives. The gradient can be calculated by the partially derivative of the objective function.\n",
        "\n",
        "$$ \\nabla l_i(w) = -y_i x_i $$\n",
        "\n",
        "\n",
        "This means, if we have a misclassified sample $x_i$, respectively $ y_i \\langle x_i,w \\rangle \\leq 0 $, update the weight vector\n",
        "$w$ by moving it in the direction of the misclassified sample.\n",
        "\n",
        "\n",
        "$$w = w + y_i x_i$$\n",
        "\n",
        "With this update rule in mind, we can start writing our perceptron algorithm in python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eiYih0TmZhr"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_91Dsdlmwvr"
      },
      "source": [
        "\n",
        "Finally we can code our SGD algorithm using our update rule. To keep it simple, we will linearly loop over the sample set. For larger data sets it makes sence, to randomly pick a sample during each iteration in the for-loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpCynLlEmxQY"
      },
      "outputs": [],
      "source": [
        "def perceptron_sgd(X, Y):\n",
        "    '''\n",
        "    # TODO: implement the below\n",
        "\n",
        "    Initialize the weight vector for the perceptron with zeros\n",
        "    Set the learning rate\n",
        "    Set the number of epochs\n",
        "    Iterate n times over the whole dataset.\n",
        "    Iterate over each sample in the dataset\n",
        "    Misclassification condition y_i * (x_i . w) <= 0\n",
        "    Update rule for the weights w = w + y_i * x_i including the learning rate\n",
        "\n",
        "    '''\n",
        "\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tIY7wrXm5FZ"
      },
      "source": [
        "### Let the Perceptron learn!\n",
        "\n",
        "Next we can execute our code to train a classifier model. To see the learning progress of the perceptron, we add a plotting feature to our algorithm, counting the total error in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJFiM-IBm9xV"
      },
      "outputs": [],
      "source": [
        "def perceptron_sgd_plot(X, Y):\n",
        "    '''\n",
        "    TODO: train perceptron and plot the total loss in each epoch. You may not use the above perceptron_sgd(X, Y) function.\n",
        "\n",
        "    :param X: data samples\n",
        "    :param Y: data labels\n",
        "    :return: weight vector as a numpy array\n",
        "    '''\n",
        "\n",
        "    # Your Implementation here\n",
        "\n",
        "    plt.plot(errors)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Total Loss')\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG3b6rbvp_T0"
      },
      "outputs": [],
      "source": [
        "X = df[['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'age', 'trestbps', 'chol', 'thalach', 'oldpeak']].to_numpy()\n",
        "y = df.loc[:, \"target\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0kQs1yip0Qm"
      },
      "outputs": [],
      "source": [
        "# TODO: Add a bias term -1 into the dataset. This is needed for the SGD to work.\n",
        "\n",
        "# add a -1 bias term to the end of each row\n",
        "bias_column =\n",
        "\n",
        "# Concatenate the original X with the bias column\n",
        "X ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz313F2ep3St"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the data to train and test with a 0.2 ratio\n",
        "\n",
        "X_train, X_val, y_train, y_val ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vza_Q_Gim_cf"
      },
      "outputs": [],
      "source": [
        "w = perceptron_sgd_plot(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoPThTyLnd0N"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARKTa6f2n4v0"
      },
      "source": [
        "\n",
        "Implement the `accuracy_score` function by considering the predictions and true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkHOtSEYnePG"
      },
      "outputs": [],
      "source": [
        "def accuracy_score(y_true, y_pred):\n",
        "    #TODO: Your implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sE-fMyLn9b9"
      },
      "source": [
        "Get the accuracy of your model using the function you implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEvjAMiUn9t_"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "predictions =\n",
        "\n",
        "print(accuracy_score(y_val, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54V2QMyQoAQr"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5cheWvWnjVR"
      },
      "source": [
        "Implement the `confusion_matrix` function to generate the confusion matrix by receiving the predicted labels, the real labels and the labels themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv6PgYmgoGtJ"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(actual, predicted, labels):\n",
        "    # TODO: Initialize the confusion matrix\n",
        "    matrix =\n",
        "\n",
        "    # TODO: Populate the confusion matrix\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhtEA4xRoKMx"
      },
      "source": [
        "Implement the following function to plot the confusion matrix obtained from the previous part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zBnY2ALoNY5"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(matrix, labels):\n",
        "    #TODO: plot the confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQhj0HS8odjN"
      },
      "source": [
        "Now plot the confusion matrix for your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNswewkkodPS"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u9hzezSo48b"
      },
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV2lhF-xo7tG"
      },
      "source": [
        "Implement the following functions to calculate precision, recall and [F1 score](https://en.wikipedia.org/wiki/F-score) using confusion matrix. Then calculate all three metrics for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H5x1seOo7-m"
      },
      "outputs": [],
      "source": [
        "def recall_score(cm):\n",
        "  #TODO: return the recall score\n",
        "\n",
        "print(recall_score(cm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-jnEGfXo-CO"
      },
      "outputs": [],
      "source": [
        "def precision_score(cm):\n",
        "  #TODO: return the precision score\n",
        "\n",
        "print(precision_score(cm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elp_Y21uo_11"
      },
      "outputs": [],
      "source": [
        "def f1_score(cm):\n",
        "  #TODO: return the f1 score\n",
        "\n",
        "print(f1_score(cm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSMb1HLNL5BB"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRS6sygsLV-G"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdyNTg7Is-Z1"
      },
      "source": [
        "To predict the target column we want to use a Naive Bayes classifier. In this section, you must implement the functions of the `MixedDataNB` class. Assume continuous features follow a normal distribution. **Hint**: You need to train a Naive Bayes model that implements the likelihood function for categorical and continuous values in two different ways. Search for Gaussian NB and Multinomial NB. **Note**: Please feel free to modify the following class and its functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EnbOik9KW9f"
      },
      "outputs": [],
      "source": [
        "class MixedDataNB:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Your Implementation here\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        TODO: Train moodel using train data\n",
        "\n",
        "        :param X: data samples as a numpy array\n",
        "        :param Y: data labels as a numpy array\n",
        "        '''\n",
        "        # Your Implementation here\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        TODO: Predict test data labels\n",
        "\n",
        "        :param X: data samples as a numpy array\n",
        "        :return: labels vector as a numpy array\n",
        "        '''\n",
        "        # Your Implementation here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCcNBC_AOddW"
      },
      "source": [
        "## Train and Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KjeHMceOJTE"
      },
      "source": [
        "\n",
        "### Data splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ljWeBvFv65G"
      },
      "source": [
        "Split the training and validation data. Separate 20% of the data for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do-NG_s2bvql"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HbVGE0BwFoZ"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uHjoYgQb5ed"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfHEirlXwyeb"
      },
      "source": [
        "### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuN_GWEhwwUN"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiVuMqFNw2rS"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOsIA_F9xf3u"
      },
      "source": [
        "Get the accuracy of your model using the function you implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5auaGaCiZ2I"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(y_val, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BmtJ-iqQhN_"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvj1QkeP3XPk"
      },
      "source": [
        "Now, using the functions you wrote, plot the confusion matrix for the model you trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nN1RNVopf-_"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Snbk3FeQyph"
      },
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGMYWaiT3rqc"
      },
      "source": [
        "Using your implemented functions in the previous section, calculate precision, recall and F1 score using confusion matrix. Then calculate all three metrics for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElFj7NblojAf"
      },
      "outputs": [],
      "source": [
        "print(recall_score(cm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MySaWgxwojsw"
      },
      "outputs": [],
      "source": [
        "print(precision_score(cm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_Sx4kv8ojz2"
      },
      "outputs": [],
      "source": [
        "print(f1_score(cm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEbb0kriPDu2"
      },
      "source": [
        "### Heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46_IPabaxvVL"
      },
      "source": [
        "By ploting the heatmap obtained for chol and oldpeak features from your model, compare the usefulness of these two features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9x7emkB6Uzn"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5E-qQQv2TgC"
      },
      "source": [
        "Train your model once by removing the chol feature and once by removing the oldpeak feature and calculate its accuracy. Compare the obtained results with the previous part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lKo-l15nI5E"
      },
      "source": [
        "Remove Chol and test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb21jrDZjy2m"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tb_XKwsnLYq"
      },
      "source": [
        "Remove oldpeak and test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IdEjL1GmDA3"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kuak-Wchp8"
      },
      "source": [
        "Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuVe6m8zcjb5"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYDwVLDqkoXc"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGNM7y2krbl"
      },
      "source": [
        "Which model did better: the perceptron or the Naive Bayes model? What factors do you think influenced the difference in their performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gof1rS14kuOG"
      },
      "source": [
        "### Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Ogh-b03oUx"
      },
      "source": [
        "# Imbalanced Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAgBI2ug4pYo"
      },
      "source": [
        "By using the model you designed and the functions you implemented, train your model on the three imbalanced data sets provided to you and calculate accuracy, recall, precision, and F1 score metrics for it each time. The confusion matrix should also be plotted each time. Finally, analyze based on the obtained results which accuracy and F1 score metrics are most appropriate for evaluating the model in imbalanced datasets. **Note:** In order to prevent code duplication, you are free to define functions and only use them with different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp4n9e5HaOVx"
      },
      "source": [
        "## First dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6PrUxRcS-Gx"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eiupha6eTf8c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXddb_7dUG5u"
      },
      "source": [
        "### Find the distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFfEYF3LUm7e"
      },
      "source": [
        "Find the number of samples from each target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWKeH1VmUpB4"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcHFkGt6UCzM"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRodEXYEUE5K"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVPEziogTMqP"
      },
      "source": [
        "### Train model and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGX1KttKTgPz"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QS80Z9fTSJH"
      },
      "source": [
        "### Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72m9_9HvTgn7"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQxSo1oTZkB"
      },
      "source": [
        "### Calculate metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6vQI8fItr3y"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM968e-qah0g"
      },
      "source": [
        "## Second dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5EY_UPRah0n"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCJt4rb8ah0n"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT-pidZNah0n"
      },
      "source": [
        "### Find the distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvMMX9Paah0n"
      },
      "source": [
        "Find the number of samples from each target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_zQTT3nah0n"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtAGBCz5ah0n"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWSWhuqkah0n"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgU9C0lcah0n"
      },
      "source": [
        "### Train model and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_0U_L9Rah0n"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L6TQSzHah0n"
      },
      "source": [
        "### Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYBVkHo4ah0n"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0XAiLBUah0o"
      },
      "source": [
        "### Calculate metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riRcbrlqah0o"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNu2VoZsak76"
      },
      "source": [
        "## Third dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXzFkXaLak8B"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfD4l1G6ak8B"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"3.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRg7HDJ-ak8B"
      },
      "source": [
        "### Find the distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lji-2CRSak8B"
      },
      "source": [
        "Find the number of samples from each target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "impG1HQFak8B"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pe45UaBak8C"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze3YZgfmak8C"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N64rNbxmak8C"
      },
      "source": [
        "### Train model and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvA0wDxYak8C"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4kXMUclak8C"
      },
      "source": [
        "### Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEaCqPgrak8C"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFjScq2yak8D"
      },
      "source": [
        "### Calculate metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8GSV1_5ak8D"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDXj0qEZ3u_"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvHYNnEEZ5to"
      },
      "source": [
        "Based on the obtained results which accuracy and F1 score metrics are most appropriate for evaluating the model in imbalanced datasets?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqGtCJLtaKhN"
      },
      "source": [
        "**Answer:**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "utNwgYmlKvfm",
        "bjntS4nxH4Hs",
        "TNo6F7XEH7p3",
        "phw5_4uEIgyY",
        "NOo1N_ZaKHPg",
        "js3fx5A2lnR6",
        "GoPThTyLnd0N",
        "54V2QMyQoAQr",
        "0u9hzezSo48b",
        "RYDwVLDqkoXc",
        "q0Ogh-b03oUx"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
